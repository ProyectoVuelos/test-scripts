import os
import time
import json
import requests
import logging
from datetime import datetime, timedelta, timezone
from pathlib import Path
from dotenv import load_dotenv
from geopy.distance import geodesic
from collections import defaultdict

# --- Logging config ---
log_dir = Path("logs")
log_dir.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_dir / "logs.log"),
        logging.StreamHandler(),
    ]
)

# --- Load environment and config ---
load_dotenv()
API_KEY = os.getenv("PROD_FR24_API_KEY")
if not API_KEY:
    logging.critical("PROD_FR24_API_KEY no est√° definida en .env. Por favor, define esta variable de entorno.")
    raise RuntimeError("Define PROD_FR24_API_KEY en .env")

HEADERS = {
    "Accept": "application/json",
    "Accept-Version": "v1",
    "Authorization": f"Bearer {API_KEY}"
}

SUMMARY_URL = "https://fr24api.flightradar24.com/api/flight-summary/full"
POSITIONS_URL = "https://fr24api.flightradar24.com/api/historic/flight-positions/full"

# Define bounds for the contiguous United States
USA_BOUNDS = "49.38,24.52,-124.77,-66.95" # North, South, West, East

try:
    with open('data/fuel_profiles.json', 'r') as f:
        FUEL_PROFILES = json.load(f)
except FileNotFoundError:
    logging.critical("No se encontr√≥ 'data/fuel_profiles.json'. Aseg√∫rate de que el archivo existe.")
    raise
except json.JSONDecodeError:
    logging.critical("Error al decodificar 'data/fuel_profiles.json'. Aseg√∫rate de que es un JSON v√°lido.")
    raise

out_dir = Path("data/flights")
out_dir.mkdir(parents=True, exist_ok=True)
logging.info(f"Directorio de salida configurado en: {out_dir}")

DAYS = 1
INTERVAL_MINUTES = 240


def calculate_distance(coords):
    """Calcula la distancia total recorrida a partir de una lista de coordenadas."""
    if not coords or len(coords) < 2:
        return 0
    try:
        distance = round(sum(geodesic(coords[i], coords[i+1]).km for i in range(len(coords)-1)), 2)
        logging.debug(f"Distancia calculada: {distance} km")
        return distance
    except Exception as e:
        logging.error(f"Error al calcular la distancia: {e}")
        return 0

def detect_phases(points, vr_thr=3, low_alt=500):
    """Detecta las fases de vuelo (despegue, ascenso, crucero, descenso, aterrizaje) y calcula sus duraciones."""
    durations = {"takeoff": 0, "climb": 0, "cruise": 0, "descent": 0, "landing": 0}
    if not points:
        logging.warning("No hay puntos para detectar fases de vuelo.")
        return durations

    for i in range(len(points) - 1):
        p0, p1 = points[i], points[i+1]
        dt = p1["timestamp"] - p0["timestamp"]
        vr = p0.get("vertical_rate", 0)
        alt = p0.get("altitude", 0)
        spd = p0.get("ground_speed", 0)

        if spd > 30 and alt < low_alt and vr > 1:
            ph = "takeoff"
        elif vr > vr_thr:
            ph = "climb"
        elif vr < -vr_thr:
            ph = "descent"
        elif alt < low_alt and spd < 50 and vr < 1:
            ph = "landing"
        else:
            ph = "cruise"
        durations[ph] += dt
    logging.debug(f"Fases de vuelo detectadas: {durations}")
    return durations

def estimate_fuel(durations, model="default"):
    """Estima el consumo de combustible por fase de vuelo."""
    fuel_rates = FUEL_PROFILES.get(model, FUEL_PROFILES.get("default"))
    if not fuel_rates:
        logging.warning(f"No se encontraron perfiles de combustible para el modelo '{model}'. Usando 'default'.")
        fuel_rates = FUEL_PROFILES.get("default")
        if not fuel_rates:
            logging.error("No se encontr√≥ el perfil de combustible 'default'.")
            return {ph: 0 for ph in durations}

    estimated_fuel = {
        ph: round((durations[ph] / 3600) * fuel_rates.get(ph, 0), 2)
        for ph in durations
    }
    logging.debug(f"Combustible estimado: {estimated_fuel}")
    return estimated_fuel

def estimate_co2_by_passenger(fuel_kg, model="default"):
    """Estima las emisiones de CO2 por pasajero."""
    co2_total = sum(fuel_kg[ph] * 3.16 for ph in fuel_kg)
    seats = FUEL_PROFILES.get(model, FUEL_PROFILES["default"]).get("seats", 150)
    if not seats:
        logging.warning(f"N√∫mero de asientos no definido para el modelo '{model}'. Usando 150 por defecto.")
        seats = 150
    co2_per_passenger = round(co2_total / seats, 2)
    logging.debug(f"CO2 total: {co2_total} kg, CO2 por pasajero: {co2_per_passenger} kg")
    return co2_per_passenger

def collect_flight_ids_for_day(day_start: datetime, interval_minutes: int):
    """
    Recolecta IDs de vuelos, callsigns/flight numbers, y puntos de posici√≥n
    para un d√≠a espec√≠fico a intervalos definidos.

    Retorna:
        dict: Un diccionario donde las claves son fr24_id y los valores son
              diccionarios con 'positions' (lista de puntos de posici√≥n) y
              'callsign_or_flight' (el callsign o flight number).
    """
    all_flight_info = defaultdict(lambda: {'positions': [], 'callsign_or_flight': None})
    iterations = int((24 * 60) / interval_minutes)
    interval = timedelta(minutes=interval_minutes)
    logging.info(f"Comenzando la recolecci√≥n de IDs, callsigns/flight numbers y posiciones detalladas para el d√≠a: {day_start.strftime('%Y-%m-%d')} en la regi√≥n de EE.UU.")

    raw_data_dir = out_dir / "raw_snapshots" / day_start.strftime("%Y%m%d")
    raw_data_dir.mkdir(parents=True, exist_ok=True)
    logging.info(f"Directorio para datos raw del d√≠a {day_start.strftime('%Y-%m-%d')}: {raw_data_dir}")

    for i in range(iterations):
        ts = int((day_start + i * interval).timestamp())
        timestamp_utc_dt = datetime.fromtimestamp(ts, timezone.utc)
        timestamp_str = timestamp_utc_dt.strftime('%Y%m%d_%H%M%S_UTC')
        logging.info(f"üõ∞ Solicitando instant√°nea en {timestamp_utc_dt.strftime('%Y-%m-%d %H:%M:%S UTC')} para EE.UU. ({USA_BOUNDS})")

        for attempt in range(1, 6):
            try:
                r = requests.get(POSITIONS_URL, headers=HEADERS, params={
                    "bounds": USA_BOUNDS,
                    "timestamp": ts
                })
                if r.status_code == 429:
                    logging.warning(f"‚ö†Ô∏è Demasiadas solicitudes (429) en el intento {attempt}. Esperando 10 segundos...")
                    time.sleep(10)
                    continue
                if r.status_code == 400:
                    logging.error(f"‚ùå Error 400 Bad Request en el timestamp {ts} (Intento {attempt}/5): {r.text}. Posiblemente data no disponible para este timestamp o fuera del rango de la clave API.")
                    time.sleep(5)
                    continue
                r.raise_for_status()

                data = r.json()

                flights_in_snapshot = data.get("positions") or data.get("data") or []
                
                # --- Guardar el JSON raw de la instant√°nea SOLO si hay datos ---
                if flights_in_snapshot:
                    raw_file_path = raw_data_dir / f"snapshot_{timestamp_str}.json"
                    try:
                        with open(raw_file_path, "w", encoding="utf-8") as f:
                            json.dump(data, f, indent=2)
                        logging.debug(f"Datos raw de la instant√°nea guardados en: {raw_file_path}")
                    except IOError as e:
                        logging.error(f"Error al guardar los datos raw de la instant√°nea {timestamp_str}: {e}")
                else:
                    logging.info(f"No se encontraron vuelos en la instant√°nea para {timestamp_str}. No se guardar√° el archivo raw.")
                # --- FIN Guardar Raw ---

                snapshot_fr24_ids = set() 

                for flight_data in flights_in_snapshot:
                    fr24_id = flight_data.get("fr24_id")
                    if fr24_id:
                        snapshot_fr24_ids.add(fr24_id) # Acumular solo los IDs
                        
                        # Obtener callsign o flight number
                        callsign_or_flight = flight_data.get("callsign") or flight_data.get("flight")
                        if callsign_or_flight:
                            # Solo actualizar si no lo tenemos ya (el primero que veamos es suficiente)
                            if all_flight_info[fr24_id]['callsign_or_flight'] is None:
                                all_flight_info[fr24_id]['callsign_or_flight'] = callsign_or_flight

                        current_lat = flight_data.get("lat")
                        current_lon = flight_data.get("lon")
                        current_alt = flight_data.get("alt", 0)
                        current_gspeed = flight_data.get("gspeed", 0)
                        current_vspeed = flight_data.get("vspeed", 0)

                        timestamp_str_api = flight_data.get("timestamp")
                        current_timestamp = None
                        if timestamp_str_api:
                            try:
                                dt_object = datetime.fromisoformat(timestamp_str_api.replace('Z', '+00:00'))
                                current_timestamp = int(dt_object.timestamp())
                            except ValueError as e:
                                logging.warning(f"No se pudo parsear el timestamp '{timestamp_str_api}' para FR24 ID {fr24_id}: {e}")

                        if current_lat is not None and current_lon is not None and current_timestamp is not None:
                             position_point = {
                                 "timestamp": current_timestamp,
                                 "latitude": current_lat,
                                 "longitude": current_lon,
                                 "vertical_rate": current_vspeed,
                                 "altitude": current_alt,
                                 "ground_speed": current_gspeed
                             }
                             all_flight_info[fr24_id]['positions'].append(position_point)
                        else:
                            logging.debug(f"Puntos de posici√≥n incompletos o faltantes para FR24 ID: {fr24_id}. Lat: {current_lat}, Lon: {current_lon}, Ts: {current_timestamp}")

                logging.info(f"‚úÖ Encontrados {len(snapshot_fr24_ids)} IDs de vuelo en la instant√°nea.")
                logging.debug(f"Puntos acumulados para esta instant√°nea hasta ahora: {sum(len(v['positions']) for v in all_flight_info.values())} puntos de {len(all_flight_info)} vuelos.")

                break
            except requests.exceptions.RequestException as e:
                logging.error(f"Error de red o HTTP al obtener vuelos en el timestamp {ts} (Intento {attempt}/5): {e}")
                time.sleep(5)
            except json.JSONDecodeError as e:
                logging.error(f"Error al decodificar JSON de la respuesta en el timestamp {ts} (Intento {attempt}/5): {e}")
                time.sleep(5)
            except Exception as e:
                logging.error(f"Error inesperado al obtener vuelos en el timestamp {ts} (Intento {attempt}/5): {e}")
                time.sleep(5)
        else:
            logging.error(f"‚ùå Fallaron todos los intentos para el timestamp {ts}. No se pudieron obtener los IDs de vuelo.")
        time.sleep(1)

    for fr24_id in all_flight_info:
        all_flight_info[fr24_id]['positions'].sort(key=lambda p: p["timestamp"])

    total_accumulated_points = sum(len(v['positions']) for v in all_flight_info.values())
    total_unique_fr24_ids = len(all_flight_info)
    logging.info(f"Se recolectaron un total de {total_unique_fr24_ids} IDs √∫nicos y se acumularon {total_accumulated_points} puntos de posici√≥n.")
    
    # Filtra vuelos que no tienen callsign_or_flight, ya que son necesarios para el summary en Modo 2
    all_flight_info_filtered = {
        fr24_id: data for fr24_id, data in all_flight_info.items() if data['callsign_or_flight']
    }
    logging.info(f"Despu√©s de filtrar, {len(all_flight_info_filtered)} vuelos tienen callsign/flight y ser√°n considerados para resumen.")
    return all_flight_info_filtered

def fetch_summaries_from_ids(flight_info_map, day_start, day_end):
    """Obtiene res√∫menes de vuelos a partir de un mapa de IDs de vuelo y sus callsigns/flight numbers.
    Utiliza el Modo 2 de la API de resumen: fechas + filtro por callsigns.
    
    Retorna:
        tuple: (list de res√∫menes de vuelos procesados, list de todos los JSON raw de respuesta)
    """
    all_processed_summaries = []
    all_raw_summary_responses = [] # Nueva lista para almacenar todas las respuestas raw
    
    fr24_ids_with_callsigns = list(flight_info_map.keys())

    if not fr24_ids_with_callsigns:
        logging.info("No hay IDs de vuelo con callsigns/flight numbers para obtener res√∫menes.")
        return [], [] # Retorna listas vac√≠as

    BATCH_SIZE = 15 # M√°ximo permitido para 'flights' o 'callsigns' en la API de summary

    logging.info(f"Comenzando a obtener res√∫menes para {len(fr24_ids_with_callsigns)} vuelos (en lotes de {BATCH_SIZE} elementos, usando callsigns/flight numbers).")

    # Los directorios raw_summaries_dir se manejan en process_day para el guardado consolidado.
    # No necesitamos crearlo aqu√≠.

    # Ajustar el rango de fechas para la b√∫squeda de res√∫menes:
    # Ampliar a un d√≠a antes y un d√≠a despu√©s del d√≠a de inter√©s
    summary_datetime_from = day_start - timedelta(hours=12) 
    summary_datetime_to = day_end + timedelta(hours=12)    

    logging.debug(f"üîç Rango de fechas para res√∫menes extendido: de {summary_datetime_from.isoformat()} a {summary_datetime_to.isoformat()}")


    for i in range(0, len(fr24_ids_with_callsigns), BATCH_SIZE):
        current_batch_fr24_ids = fr24_ids_with_callsigns[i:i + BATCH_SIZE]
        
        # Construir la lista de callsigns/flight numbers para el lote actual
        current_batch_callsigns_or_flights = [
            flight_info_map[fr24_id]['callsign_or_flight'] 
            for fr24_id in current_batch_fr24_ids 
            if flight_info_map[fr24_id]['callsign_or_flight']
        ]

        if not current_batch_callsigns_or_flights:
            logging.debug(f"Saltando lote {i} porque no hay callsigns/flight numbers v√°lidos.")
            continue

        current_batch_callsigns_str = ",".join(current_batch_callsigns_or_flights)
        
        current_offset = 0
        max_retries = 5
        initial_wait_time = 5 # segundos
        
        while True: # Bucle de paginaci√≥n
            for attempt in range(1, max_retries + 1):
                params = {
                    "flights": current_batch_callsigns_str, # Usamos 'flights' con callsigns/flight numbers
                    "flight_datetime_from": summary_datetime_from.isoformat(timespec='seconds'),
                    "flight_datetime_to": summary_datetime_to.isoformat(timespec='seconds'),
                    "limit": 100,
                    "offset": current_offset
                }
                logging.debug(f"üîó Solicitando res√∫menes para lote de callsigns '{current_batch_callsigns_or_flights[0]}...' con par√°metros {params} (Intento {attempt}/{max_retries})")

                try:
                    r = requests.get(SUMMARY_URL, headers=HEADERS, params=params)
                    
                    if r.status_code == 429:
                        wait_time = initial_wait_time * (2 ** (attempt - 1))
                        logging.warning(f"‚ö†Ô∏è Demasiadas solicitudes (429) en el intento {attempt}/{max_retries} para lote de res√∫menes '{current_batch_callsigns_or_flights[0]}...'. Esperando {wait_time:.1f} segundos antes de reintentar...")
                        time.sleep(wait_time)
                        continue
                    
                    r.raise_for_status()
                    
                    response_json = r.json()
                    
                    # Almacenar la respuesta raw completa
                    all_raw_summary_responses.append(response_json)

                    data = []
                    if isinstance(response_json, dict) and "data" in response_json and isinstance(response_json["data"], list):
                        data = response_json["data"]
                    elif isinstance(response_json, list): 
                        logging.warning(f"La respuesta de la API de resumen fue una lista directa para el lote '{current_batch_callsigns_str}', no un diccionario con 'data'. Estructura inesperada pero manejada. Respuesta completa: {json.dumps(response_json, indent=2)}")
                        data = response_json
                    else:
                        logging.error(
                            f"‚ùå La respuesta de la API de resumen no coincide con la estructura documentada (dict con clave 'data' que contiene una lista), ni fue una lista directa. "
                            f"Tipo recibido: {type(response_json)}. "
                            f"Lote de callsigns: '{current_batch_callsigns_str}'. Offset: {current_offset}. "
                            f"Respuesta completa: {json.dumps(response_json, indent=2)}. "
                            f"Asumiendo lista vac√≠a."
                        )
                        data = []

                    # Ya no guardamos el JSON raw del summary aqu√≠, se har√° al final del d√≠a.
                    
                    if not data:
                        logging.info(f"No se encontraron res√∫menes en la respuesta para el lote '{current_batch_callsigns_or_flights[0]}...' (offset {current_offset}). Finalizando paginaci√≥n para este lote.")
                        break
                    
                    all_processed_summaries.extend(data)
                    current_offset += len(data)
                    logging.info(f"‚úÖ Obtenidos {len(data)} res√∫menes para el lote '{current_batch_callsigns_or_flights[0]}...'. Total acumulado: {len(all_processed_summaries)} res√∫menes.")
                    time.sleep(1)

                    break # Romper el bucle de reintentos y pasar a la siguiente p√°gina (o lote si no hay m√°s p√°ginas)
                
                except requests.exceptions.HTTPError as http_err:
                    error_detail = r.text if r.text else str(http_err)
                    logging.error(f"‚ùå Error HTTP {r.status_code} {r.reason} al obtener res√∫menes para el lote de callsigns '{current_batch_callsigns_str}' (offset {current_offset}): Detalles: {error_detail} (Intento {attempt}/{max_retries})")
                    
                    if r.status_code == 400:
                        logging.warning(f"Error 400 Bad Request para el lote. Saltando al siguiente lote de res√∫menes.")
                        break # Romper reintentos y pasar al siguiente lote de callsigns
                    
                    if attempt == max_retries:
                        logging.error(f"Agota dos los intentos ({max_retries}) para el lote '{current_batch_callsigns_str}' debido a error HTTP. Saltando al siguiente lote.")
                        break # Romper reintentos y pasar al siguiente lote de callsigns
                    time.sleep(initial_wait_time)

                except requests.exceptions.RequestException as e:
                    logging.error(f"‚ùå Error de red al obtener res√∫menes para el lote de callsigns '{current_batch_callsigns_str}' (offset {current_offset}): {e} (Intento {attempt}/{max_retries})")
                    if attempt == max_retries:
                        logging.error(f"Agota dos los intentos ({max_retries}) para el lote '{current_batch_callsigns_str}' debido a error de red. Saltando al siguiente lote.")
                        break # Romper reintentos y pasar al siguiente lote de callsigns
                    time.sleep(initial_wait_time)
                    
                except json.JSONDecodeError as e:
                    logging.error(f"‚ùå Error al decodificar JSON de la respuesta del resumen para el lote de callsigns '{current_batch_callsigns_str}' (offset {current_offset}): {e} (Intento {attempt}/{max_retries}). Saltando al siguiente lote de res√∫menes.")
                    break # Romper reintentos y pasar al siguiente lote de callsigns
                
                except Exception as e:
                    logging.critical(f"‚ùå Error inesperado y cr√≠tico al obtener res√∫menes para el lote de callsigns '{current_batch_callsigns_str}' (offset {current_offset}): {e} (Intento {attempt}/{max_retries}). Saltando al siguiente lote.", exc_info=True)
                    break # Romper reintentos y pasar al siguiente lote de callsigns

            else: # Este else se ejecuta si el bucle for termina sin un 'break' (es decir, agot√≥ los intentos)
                logging.error(f"‚ùå Fallaron todos los {max_retries} intentos para el lote de res√∫menes '{current_batch_callsigns_str}' (offset {current_offset}). No se pudieron obtener res√∫menes para este lote.")
            
            # L√≥gica para controlar el bucle de paginaci√≥n (while True)
            if 'data' not in locals() or not data: # Si 'data' no se pudo extraer o est√° vac√≠o, salir del bucle de paginaci√≥n
                break 
            # Si hubo un Bad Request en el √∫ltimo intento, salir del bucle de paginaci√≥n para este lote
            if 'r' in locals() and r.status_code == 400: 
                break
            # Si se agotaron los reintentos y no se obtuvo data, salir del bucle de paginaci√≥n
            if 'attempt' in locals() and attempt == max_retries and not data:
                 break

    logging.info(f"Finalizada la obtenci√≥n de res√∫menes. Total: {len(all_processed_summaries)}.")
    return all_processed_summaries, all_raw_summary_responses

def process_day(day_start: datetime):
    """Procesa los datos de vuelos para un d√≠a completo, usando datos de posici√≥n acumulados."""
    date_str = day_start.strftime("%Y%m%d")
    day_end = day_start + timedelta(days=1)
    logging.info(f"Comenzando el procesamiento de datos para el d√≠a: {day_start.strftime('%Y-%m-%d')}")

    # Paso 1: Recolectar IDs de vuelos y puntos de posici√≥n
    accumulated_flight_data = collect_flight_ids_for_day(day_start, INTERVAL_MINUTES)
    flight_ids_from_snapshots_with_data = list(accumulated_flight_data.keys())
    logging.info(f"Se encontraron {len(flight_ids_from_snapshots_with_data)} IDs de vuelo con datos y callsigns/flight numbers en las instant√°neas para el d√≠a {date_str}.")


    if not flight_ids_from_snapshots_with_data:
        logging.warning(f"No se encontraron IDs de vuelo o datos de posici√≥n en las instant√°neas para el d√≠a {date_str}. Saltando el procesamiento para este d√≠a.")
        return

    # Paso 2: Obtener res√∫menes de vuelos usando los IDs recolectados
    # Ahora fetch_summaries_from_ids devuelve los res√∫menes procesados y las respuestas raw
    summaries, all_raw_summary_responses = fetch_summaries_from_ids(accumulated_flight_data, day_start, day_end) 
    summary_map = {s.get("fr24_id"): s for s in summaries if s.get("fr24_id")}
    
    logging.info(f"Se obtuvieron {len(summaries)} res√∫menes de vuelos de la API de resumen.")
    logging.info(f"De esos, {len(summary_map)} res√∫menes √∫nicos se mapearon para combinaci√≥n.")

    # --- Guardar TODAS las respuestas raw de los summaries en un √öNICO archivo por d√≠a ---
    if all_raw_summary_responses:
        raw_summaries_dir = out_dir / "raw_summaries" / day_start.strftime("%Y%m%d")
        raw_summaries_dir.mkdir(parents=True, exist_ok=True) # Asegurarse de que el directorio exista
        
        consolidated_raw_summary_file = raw_summaries_dir / f"all_raw_summaries_{date_str}.json"
        try:
            with open(consolidated_raw_summary_file, "w", encoding="utf-8") as f:
                json.dump(all_raw_summary_responses, f, indent=2)
            logging.info(f"Todas las respuestas raw de los res√∫menes del d√≠a guardadas en: {consolidated_raw_summary_file}")
        except IOError as e:
            logging.error(f"Error al guardar el archivo consolidado de res√∫menes raw en {consolidated_raw_summary_file}: {e}")
    else:
        logging.info(f"No se obtuvieron respuestas raw de res√∫menes para el d√≠a {date_str}. No se guardar√° el archivo consolidado.")
    # --- FIN Guardar Raw Consolidado ---

    summary_file_path = out_dir / f"flights_summary_{date_str}.json"
    try:
        with open(summary_file_path, "w", encoding="utf-8") as f:
            json.dump(summaries, f, indent=2)
        logging.info(f"Res√∫menes de vuelos combinados guardados en: {summary_file_path}")
    except IOError as e:
        logging.error(f"Error al guardar los res√∫menes combinados en {summary_file_path}: {e}")

    processed_flights = []
    logging.info(f"Procesando {len(accumulated_flight_data)} vuelos con datos de posici√≥n acumulados para enriquecerlos con res√∫menes.")

    for fid, flight_data in accumulated_flight_data.items():
        pts = flight_data['positions'] # Obtener solo las posiciones
        callsign_or_flight = flight_data['callsign_or_flight'] # Obtener el callsign/flight

        if not pts:
            logging.warning(f"No hay puntos de posici√≥n para el vuelo FR24 ID: {fid}. Saltando c√°lculos para este vuelo.")
            continue

        s = summary_map.get(fid, {}) # Obtiene el resumen, si existe. Si no, es un diccionario vac√≠o.

        # Si no se encontr√≥ un resumen para este vuelo, loguearlo y saltarlo o continuar con datos parciales
        if not s:
            logging.debug(f"‚ÑπÔ∏è No se encontr√≥ resumen detallado de la API para el vuelo FR24 ID: {fid} (Callsign: {callsign_or_flight}). Se procesar√° con datos parciales.")
            # Dependiendo de tu estrategia, podr√≠as optar por saltar este vuelo aqu√≠:
            # continue 
        
        coords = [(p["latitude"], p["longitude"]) for p in pts if p["latitude"] is not None and p["longitude"] is not None]
        dist = calculate_distance(coords) if coords else 0
        durs = detect_phases(pts)
        
        aircraft_type_from_summary = s.get("type") 
        aircraft_model = s.get("aircraft", {}).get("model") 
        
        model_for_fuel = aircraft_type_from_summary or aircraft_model or "default"

        fuel = estimate_fuel(durs, model_for_fuel)
        co2_by_phase = {ph: round(fuel[ph] * 3.16, 2) for ph in fuel}
        co2_total = round(sum(co2_by_phase.values()), 2)
        co2_per_passenger = estimate_co2_by_passenger(fuel, model_for_fuel)

        rec = {
            "fr24_id": fid,
            "flight": s.get("flight"),
            "callsign": s.get("callsign") or callsign_or_flight, # Preferir el de summary, si no, el de la instant√°nea
            "aircraft_model": model_for_fuel,
            "aircraft_reg": s.get("reg"),
            "departure": s.get("orig_icao"),
            "arrival": s.get("dest_icao"),
            "distance_km": dist,
            "phase_durations_s": durs,
            "fuel_estimated_kg": fuel,
            "co2_estimated_kg": co2_by_phase,
            "co2_total_kg": co2_total,
            "co2_per_passenger_kg": co2_per_passenger,
            "raw_flight_path_points": pts,
            "circle_distance": s.get("circle_distance"),
        }
        processed_flights.append(rec)

        flight_detail_file_path = out_dir / f"{fid}_detailed_path_{date_str}.json"
        try:
            with open(flight_detail_file_path, "w", encoding="utf-8") as f:
                json.dump(pts, f, indent=2)
            logging.debug(f"Puntos de posici√≥n detallados para el vuelo {fid} guardados en: {flight_detail_file_path}")
        except IOError as e:
            logging.error(f"Error al guardar los puntos de posici√≥n del vuelo {fid} en {flight_detail_file_path}: {e}")

    time.sleep(1)

    processed_file_path = out_dir / f"flights_processed_{date_str}.json"
    try:
        with open(processed_file_path, "w", encoding="utf-8") as f:
            json.dump(processed_flights, f, indent=2)
        logging.info(f"Datos de vuelos procesados guardados en: {processed_file_path}")
    except IOError as e:
        logging.error(f"Error al guardar los vuelos procesados en {processed_file_path}: {e}")

    logging.info(f"‚úÖ Finalizado el procesamiento de {len(processed_flights)} vuelos para {date_str}.")

if __name__ == "__main__":
    today_utc_midnight = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
    days_to_offset_from_today = 1 # Para procesar el d√≠a de ayer UTC (ej. hoy 04/07, se procesa 03/07)
    start_processing_day = today_utc_midnight - timedelta(days=days_to_offset_from_today)

    logging.info("Iniciando el script de recolecci√≥n y procesamiento de datos de FlightRadar24.")
    for day_offset in range(DAYS):
        day = start_processing_day
        logging.info(f"\n--- üìÖ Iniciando procesamiento para el d√≠a: {day.strftime('%Y-%m-%d')} ---")
        try:
            process_day(day)
        except Exception as e:
            logging.critical(f"‚ùå Error cr√≠tico al procesar el d√≠a {day.strftime('%Y-%m-%d')}: {e}", exc_info=True)
    logging.info("Procesamiento de datos de FlightRadar24 finalizado.")